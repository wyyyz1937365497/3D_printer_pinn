#!/usr/bin/env python3
"""
ç‹¬ç«‹çš„æ¨¡å‹æµ‹è¯•ä¸å¯è§†åŒ–è„šæœ¬ï¼ˆä¿®å¤ç‰ˆï¼‰
ä¿®å¤ CUDA OOM é—®é¢˜ï¼šå‡å° batch_size å¹¶ä¼˜åŒ–å†…å­˜ä½¿ç”¨
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import os
import gc

# ==================== æ¨¡å‹å®šä¹‰ ====================
class TemporalBlock(nn.Module):
    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):
        super(TemporalBlock, self).__init__()
        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size,
                              stride=stride, padding=padding, dilation=dilation)
        self.relu1 = nn.ReLU()
        self.dropout1 = nn.Dropout(dropout)
        self.net = nn.Sequential(self.conv1, self.relu1, self.dropout1)
        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None
        self.relu = nn.ReLU()
        self.kernel_size = kernel_size
        self.dilation = dilation

    def forward(self, x):
        out = self.net(x)
        pad = (self.kernel_size - 1) * self.dilation
        out = out[:, :, :-pad]
        res = x if self.downsample is None else self.downsample(x)
        return self.relu(out + res)


class TCN(nn.Module):
    def __init__(self, num_inputs, num_channels, kernel_size=3, dropout=0.2):
        super(TCN, self).__init__()
        layers = []
        num_levels = len(num_channels)
        for i in range(num_levels):
            dilation_size = 2 ** i
            in_channels = num_inputs if i == 0 else num_channels[i - 1]
            out_channels = num_channels[i]
            padding = (kernel_size - 1) * dilation_size
            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1,
                                   dilation=dilation_size, padding=padding, dropout=dropout)]
        self.network = nn.Sequential(*layers)

    def forward(self, x):
        x = x.transpose(1, 2)
        out = self.network(x)
        return out.transpose(1, 2)


class TCNLSTMModel(nn.Module):
    def __init__(self, input_dim, tcn_channels, hidden_dim, output_dim):
        super(TCNLSTMModel, self).__init__()
        self.tcn = TCN(input_dim, tcn_channels)
        tcn_output_dim = tcn_channels[-1]
        self.lstm = nn.LSTM(tcn_output_dim, hidden_dim, num_layers=2,
                           batch_first=True, dropout=0.1, bidirectional=False)
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        tcn_out = self.tcn(x)
        lstm_out, (h_n, c_n) = self.lstm(tcn_out)
        last_step_out = lstm_out[:, -1, :]
        prediction = self.fc(last_step_out)
        return prediction


# ==================== æ•°æ®åŠ è½½å™¨ ====================
class SimpleMMapDataset(torch.utils.data.Dataset):
    def __init__(self, X_mmap, Y_mmap):
        self.X = X_mmap
        self.Y = Y_mmap

    def __len__(self):
        return self.X.shape[0]

    def __getitem__(self, idx):
        return self.X[idx].copy(), self.Y[idx].copy()


# ==================== ä¸»å‡½æ•° ====================
def load_model_and_visualize(
    model_path='best_tcn_lstm_model.pth',
    cache_dir='./data_cache/',
    device='cuda' if torch.cuda.is_available() else 'cpu',
    batch_size=1024,  # ğŸ”§ å‡å° batch_size ä» 8192 -> 1024
    num_samples_to_plot=200,
    save_path='image/prediction_visualization.png',
    save_metrics='image/metrics_report.txt'
):
    """
    åŠ è½½æ¨¡å‹å¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆä¿®å¤ OOM é—®é¢˜ï¼‰
    
    å‚æ•°:
        model_path: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
        cache_dir: æ•°æ®ç¼“å­˜ç›®å½•
        device: è¿è¡Œè®¾å¤‡ ('cuda' æˆ– 'cpu')
        batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆå‡å°ä»¥é¿å… OOMï¼‰
        num_samples_to_plot: å¯è§†åŒ–æ—¶æ˜¾ç¤ºçš„æ ·æœ¬æ•°é‡
        save_path: å›¾ç‰‡ä¿å­˜è·¯å¾„
        save_metrics: æŒ‡æ ‡æŠ¥å‘Šä¿å­˜è·¯å¾„
    """
    print("=" * 70)
    print("ğŸ¨ æ¨¡å‹å¯è§†åŒ–è„šæœ¬ï¼ˆä¿®å¤ç‰ˆï¼‰")
    print("=" * 70)
    
    # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    if not os.path.exists(cache_dir):
        raise FileNotFoundError(f"âŒ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {cache_dir}")
    
    print(f"âœ… æ¨¡å‹æ–‡ä»¶: {model_path}")
    print(f"âœ… ç¼“å­˜ç›®å½•: {cache_dir}")
    print(f"âœ… è®¾å¤‡: {device}")
    print(f"âœ… Batch Size: {batch_size}")
    
    # 2. æ¸…ç† GPU ç¼“å­˜
    if device == 'cuda':
        torch.cuda.empty_cache()
        print("ğŸ§¹ å·²æ¸…ç† GPU ç¼“å­˜")
    
    # 3. åŠ è½½å½’ä¸€åŒ–å‚æ•°
    print("\nğŸ“Š åŠ è½½å½’ä¸€åŒ–å‚æ•°...")
    scaler_path = os.path.join(cache_dir, 'scaler_stats.npz')
    if not os.path.exists(scaler_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°å½’ä¸€åŒ–å‚æ•°æ–‡ä»¶: {scaler_path}")
    
    scaler_data = np.load(scaler_path)
    mean_X = scaler_data['mean_X']
    std_X = scaler_data['std_X']
    mean_Y = scaler_data['mean_Y']
    std_Y = scaler_data['std_Y']
    
    print(f"   Input mean: {mean_X}")
    print(f"   Input std:  {std_X}")
    print(f"   Target mean: {mean_Y}")
    print(f"   Target std:  {std_Y}")
    
    # 4. åŠ è½½éªŒè¯æ•°æ®
    print("\nğŸ“‚ åŠ è½½éªŒè¯æ•°æ®...")
    val_X = np.load(os.path.join(cache_dir, 'val_X.npy'), mmap_mode='r')
    val_Y = np.load(os.path.join(cache_dir, 'val_Y.npy'), mmap_mode='r')
    
    print(f"   éªŒè¯æ•°æ®å½¢çŠ¶: X={val_X.shape}, Y={val_Y.shape}")
    
    # 5. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    val_dataset = SimpleMMapDataset(val_X, val_Y)
    val_loader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=False  # ğŸ”§ å…³é—­ pin_memory ä»¥å‡å°‘å†…å­˜å ç”¨
    )
    
    # 6. åˆ›å»ºæ¨¡å‹
    print("\nğŸ—ï¸  åˆ›å»ºæ¨¡å‹...")
    input_dim = len(mean_X)
    output_dim = len(mean_Y)
    tcn_channels = [64, 64, 128]
    hidden_dim = 128
    
    model = TCNLSTMModel(input_dim, tcn_channels, hidden_dim, output_dim)
    
    # 7. åŠ è½½æ¨¡å‹æƒé‡
    print(f"ğŸ“¦ åŠ è½½æ¨¡å‹æƒé‡: {model_path}")
    state_dict = torch.load(model_path, map_location=device)
    
    # å¦‚æœæ¨¡å‹æ˜¯ç”¨ DataParallel ä¿å­˜çš„ï¼Œå»æ‰ 'module.' å‰ç¼€
    new_state_dict = {}
    for k, v in state_dict.items():
        if k.startswith('module.'):
            new_state_dict[k[7:]] = v
        else:
            new_state_dict[k] = v
    model.load_state_dict(new_state_dict)
    
    model = model.to(device)
    model.eval()
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # 8. è¿›è¡Œé¢„æµ‹
    print("\nğŸ”® å¼€å§‹é¢„æµ‹...")
    all_preds = []
    all_targets = []
    total_loss = 0.0
    criterion = nn.MSELoss()
    
    # ğŸ”§ ä½¿ç”¨æ··åˆç²¾åº¦æ¨ç†
    use_amp = device == 'cuda'
    
    with torch.no_grad():
        for batch_idx, (batch_X, batch_Y) in enumerate(val_loader):
            batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)
            
            # ğŸ”§ ä½¿ç”¨ autocast å‡å°‘å†…å­˜å ç”¨
            if use_amp:
                with torch.cuda.amp.autocast():
                    outputs = model(batch_X)
                    loss = criterion(outputs, batch_Y)
            else:
                outputs = model(batch_X)
                loss = criterion(outputs, batch_Y)
            
            total_loss += loss.item() * batch_X.size(0)
            
            # ä¿å­˜ç»“æœï¼ˆç«‹å³è½¬ç§»åˆ° CPUï¼‰
            all_preds.append(outputs.cpu().numpy())
            all_targets.append(batch_Y.cpu().numpy())
            
            # ğŸ”§ ç«‹å³æ¸…ç† GPU å†…å­˜
            del outputs, loss, batch_X, batch_Y
            if device == 'cuda' and batch_idx % 5 == 0:
                torch.cuda.empty_cache()
            
            if (batch_idx + 1) % 10 == 0:
                print(f"   Batch {batch_idx+1}/{len(val_loader)}")
    
    # 9. åˆå¹¶æ‰€æœ‰é¢„æµ‹
    print("\nğŸ”„ åˆå¹¶é¢„æµ‹ç»“æœ...")
    preds = np.vstack(all_preds)
    targets = np.vstack(all_targets)
    
    # ğŸ”§ æ¸…ç†åˆ—è¡¨ä»¥é‡Šæ”¾å†…å­˜
    del all_preds, all_targets
    gc.collect()
    if device == 'cuda':
        torch.cuda.empty_cache()
    
    # 10. è®¡ç®—å¹³å‡æŸå¤±
    avg_loss = total_loss / len(val_dataset)
    print(f"ğŸ“Š éªŒè¯é›†å¹³å‡æŸå¤±: {avg_loss:.6f}")
    
    # 11. åå½’ä¸€åŒ–
    print("ğŸ”„ åå½’ä¸€åŒ–...")
    preds_real = preds * std_Y + mean_Y
    targets_real = targets * std_Y + mean_Y
    
    # ğŸ”§ æ¸…ç†ä¸­é—´å˜é‡
    del preds, targets
    gc.collect()
    if device == 'cuda':
        torch.cuda.empty_cache()
    
    # 12. è®¡ç®—æ¯ä¸ªç‰¹å¾çš„æŒ‡æ ‡
    print("\nğŸ“ˆ è®¡ç®—å„ç‰¹å¾æŒ‡æ ‡...")
    feature_names = ['temperature_C', 'vibration_disp_m', 'vibration_vel_m_s',
                     'motor_current_A', 'pressure_bar', 'acoustic_signal']
    
    metrics_list = []
    for i, name in enumerate(feature_names):
        pred_i = preds_real[:, i]
        target_i = targets_real[:, i]
        
        mse = np.mean((pred_i - target_i) ** 2)
        mae = np.mean(np.abs(pred_i - target_i))
        rmse = np.sqrt(mse)
        
        # è®¡ç®—RÂ²
        ss_res = np.sum((target_i - pred_i) ** 2)
        ss_tot = np.sum((target_i - np.mean(target_i)) ** 2)
        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
        
        # è®¡ç®—MAPEï¼ˆé¿å…é™¤é›¶ï¼‰
        mask = np.abs(target_i) > 1e-6
        mape = np.mean(np.abs((target_i[mask] - pred_i[mask]) / target_i[mask])) * 100 if np.any(mask) else 0
        
        metrics_list.append({
            'feature': name,
            'MSE': mse,
            'MAE': mae,
            'RMSE': rmse,
            'RÂ²': r2,
            'MAPE (%)': mape
        })
    
    # 13. ç”Ÿæˆå¯è§†åŒ–
    print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    
    # åˆ›å»ºå›¾ç‰‡ä¿å­˜ç›®å½•
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    # å¤§å›¾ï¼šæ‰€æœ‰6ä¸ªç‰¹å¾
    fig, axes = plt.subplots(3, 2, figsize=(16, 12))
    axes = axes.flatten()
    
    n_plot = min(num_samples_to_plot, len(preds_real))
    
    for i, name in enumerate(feature_names):
        ax = axes[i]
        ax.plot(targets_real[:n_plot, i], label='Ground Truth', alpha=0.7, linewidth=2)
        ax.plot(preds_real[:n_plot, i], label='Prediction', linestyle='--', alpha=0.7, linewidth=1.5)
        ax.set_title(f'{name}\nRMSE: {metrics_list[i]["RMSE"]:.4f} | RÂ²: {metrics_list[i]["RÂ²"]:.4f}', 
                    fontsize=11, fontweight='bold')
        ax.set_xlabel('Sample Index')
        ax.set_ylabel('Value')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {save_path}")
    plt.show()
    
    # 14. ç”Ÿæˆæ•£ç‚¹å›¾ï¼ˆé¢„æµ‹ vs çœŸå®å€¼ï¼‰
    scatter_path = save_path.replace('.png', '_scatter.png')
    fig2, axes2 = plt.subplots(3, 2, figsize=(16, 12))
    axes2 = axes2.flatten()
    
    for i, name in enumerate(feature_names):
        ax = axes2[i]
        ax.scatter(targets_real[:, i], preds_real[:, i], alpha=0.1, s=1)
        ax.plot([targets_real[:, i].min(), targets_real[:, i].max()],
                [targets_real[:, i].min(), targets_real[:, i].max()], 
                'r--', linewidth=2, label='Perfect Prediction')
        ax.set_xlabel('Ground Truth')
        ax.set_ylabel('Prediction')
        ax.set_title(f'{name} - Scatter Plot', fontsize=11, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.axis('equal')
    
    plt.tight_layout()
    plt.savefig(scatter_path, dpi=150, bbox_inches='tight')
    print(f"âœ… æ•£ç‚¹å›¾å·²ä¿å­˜: {scatter_path}")
    plt.show()
    
    # 15. ä¿å­˜æŒ‡æ ‡æŠ¥å‘Š
    print("\nğŸ“ ä¿å­˜æŒ‡æ ‡æŠ¥å‘Š...")
    os.makedirs(os.path.dirname(save_metrics), exist_ok=True)
    
    with open(save_metrics, 'w', encoding='utf-8') as f:
        f.write("=" * 70 + "\n")
        f.write("æ¨¡å‹æ€§èƒ½æŒ‡æ ‡æŠ¥å‘Š\n")
        f.write("=" * 70 + "\n\n")
        f.write(f"æ¨¡å‹æ–‡ä»¶: {model_path}\n")
        f.write(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}\n")
        f.write(f"éªŒè¯é›†å¹³å‡æŸå¤±: {avg_loss:.6f}\n\n")
        
        f.write("-" * 70 + "\n")
        f.write("å„ç‰¹å¾è¯¦ç»†æŒ‡æ ‡\n")
        f.write("-" * 70 + "\n\n")
        
        for metrics in metrics_list:
            f.write(f"ç‰¹å¾: {metrics['feature']}\n")
            f.write(f"  MSE (å‡æ–¹è¯¯å·®):     {metrics['MSE']:.6f}\n")
            f.write(f"  MAE (å¹³å‡ç»å¯¹è¯¯å·®): {metrics['MAE']:.6f}\n")
            f.write(f"  RMSE (å‡æ–¹æ ¹è¯¯å·®):  {metrics['RMSE']:.6f}\n")
            f.write(f"  RÂ² (å†³å®šç³»æ•°):      {metrics['RÂ²']:.6f}\n")
            f.write(f"  MAPE (å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®): {metrics['MAPE (%)']:.2f}%\n\n")
    
    print(f"âœ… æŒ‡æ ‡æŠ¥å‘Šå·²ä¿å­˜: {save_metrics}")
    
    # 16. æ‰“å°æ‘˜è¦
    print("\n" + "=" * 70)
    print("ğŸ“Š æ€§èƒ½æ‘˜è¦")
    print("=" * 70)
    for metrics in metrics_list:
        print(f"{metrics['feature']}:")
        print(f"  RMSE: {metrics['RMSE']:.4f}, RÂ²: {metrics['RÂ²']:.4f}, MAPE: {metrics['MAPE (%)']:.2f}%")
    
    print("\n" + "=" * 70)
    print("âœ… å¯è§†åŒ–å®Œæˆï¼")
    print("=" * 70)
    
    return metrics_list, avg_loss


if __name__ == "__main__":
    # ğŸ”§ å¯ä»¥æ ¹æ® GPU å†…å­˜æƒ…å†µè°ƒæ•´ batch_size
    # å¦‚æœè¿˜æ˜¯ OOMï¼Œå¯ä»¥ç»§ç»­å‡å°åˆ° 512 æˆ– 256
    metrics, val_loss = load_model_and_visualize(
        model_path='best_tcn_lstm_model.pth',
        cache_dir='./data_cache/',
        device='cuda' if torch.cuda.is_available() else 'cpu',
        batch_size=1024,  # ä» 8192 å‡å°åˆ° 1024ï¼ˆå¦‚æœè¿˜æ˜¯ OOMï¼Œæ”¹ä¸º 512 æˆ– 256ï¼‰
        num_samples_to_plot=200,
        save_path='image/prediction_visualization.png',
        save_metrics='image/metrics_report.txt'
    )

