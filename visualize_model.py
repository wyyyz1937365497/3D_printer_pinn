#!/usr/bin/env python3
"""
Transformer PINN æ¨¡å‹è¯„ä¼°ä¸å¯è§†åŒ–è„šæœ¬ï¼ˆå†…å­˜ç›´æ¥è¯»å–ç‰ˆï¼‰
æ”¯æŒç›´æ¥ä»å†…å­˜è¯»å–æ•°æ®ï¼Œä¸ä¾èµ–ç¡¬ç›˜ç¼“å­˜æ–‡ä»¶
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import os
import gc
import argparse
from torch.utils.data import DataLoader
from torch.amp import autocast

# ==================== é…ç½®å‚æ•° ====================
class Config:
    def __init__(self):
        self.seq_len = 200
        self.input_cols = ['ctrl_T_target', 'ctrl_speed_set', 'ctrl_heater_base']
        self.target_cols = ['temperature_C', 'vibration_disp_m', 'vibration_vel_m_s',
                          'motor_current_A', 'pressure_bar', 'acoustic_signal']

# ==================== æ¨¡å‹å®šä¹‰ ====================
class PositionalEncoding(nn.Module):
    """ä½ç½®ç¼–ç """
    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0)
        self.register_buffer('pe', pe)

    def forward(self, x):
        return x + self.pe[:, :x.size(1), :]

class PrinterPINN(nn.Module):
    """3Dæ‰“å°æœºç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ"""
    def __init__(self, input_dim, output_dim, seq_len=200):
        super(PrinterPINN, self).__init__()
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.seq_len = seq_len
        
        # è¾“å…¥æŠ•å½±å±‚
        self.input_proj = nn.Linear(input_dim, 256)
        
        # ä½ç½®ç¼–ç 
        self.pos_encoder = PositionalEncoding(256, seq_len)
        
        # Transformerç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=256,
            nhead=8,
            dim_feedforward=1024,
            dropout=0.1,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=6)
        
        # è¾“å‡ºå±‚
        self.fc = nn.Linear(256, output_dim)

    def forward(self, x):
        # è¾“å…¥æŠ•å½±
        x = self.input_proj(x)
        
        # æ·»åŠ ä½ç½®ç¼–ç 
        x = self.pos_encoder(x)
        
        # Transformerå¤„ç†
        x = self.transformer(x)
        
        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        x = x[:, -1, :]
        
        # è¾“å‡ºå±‚
        prediction = self.fc(x)
        return prediction

# ==================== æ•°æ®åŠ è½½å™¨ ====================
class MemoryDataset(torch.utils.data.Dataset):
    """ç›´æ¥ä»å†…å­˜åŠ è½½æ•°æ®çš„Dataset"""
    def __init__(self, X, Y):
        self.X = torch.from_numpy(X)
        self.Y = torch.from_numpy(Y)

    def __len__(self):
        return self.X.shape[0]

    def __getitem__(self, idx):
        return self.X[idx], self.Y[idx]

# ==================== ä¸»å‡½æ•° ====================
def load_model_and_visualize(
    model_path='best_pinn_model.pth',
    cache_dir='./data_cache/',
    device='cuda' if torch.cuda.is_available() else 'cpu',
    batch_size=1024,
    num_samples_to_plot=200,
    save_path='image/pinn_prediction_visualization.png',
    save_metrics='image/pinn_metrics_report.txt'
):
    """
    åŠ è½½ Transformer PINN æ¨¡å‹å¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    
    å‚æ•°:
        model_path: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
        cache_dir: æ•°æ®ç¼“å­˜ç›®å½•ï¼ˆç”¨äºå½’ä¸€åŒ–å‚æ•°ï¼‰
        device: è¿è¡Œè®¾å¤‡ ('cuda' æˆ– 'cpu')
        batch_size: æ‰¹æ¬¡å¤§å°
        num_samples_to_plot: å¯è§†åŒ–æ—¶æ˜¾ç¤ºçš„æ ·æœ¬æ•°é‡
        save_path: å›¾ç‰‡ä¿å­˜è·¯å¾„
        save_metrics: æŒ‡æ ‡æŠ¥å‘Šä¿å­˜è·¯å¾„
    """
    print("=" * 70)
    print("ğŸ¨ Transformer PINN æ¨¡å‹å¯è§†åŒ–è„šæœ¬ï¼ˆå†…å­˜ç›´æ¥è¯»å–ç‰ˆï¼‰")
    print("=" * 70)
    
    # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    if not os.path.exists(cache_dir):
        raise FileNotFoundError(f"âŒ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {cache_dir}")
    
    print(f"âœ… æ¨¡å‹æ–‡ä»¶: {model_path}")
    print(f"âœ… ç¼“å­˜ç›®å½•: {cache_dir}")
    print(f"âœ… è®¾å¤‡: {device}")
    print(f"âœ… Batch Size: {batch_size}")
    
    # 2. æ¸…ç† GPU ç¼“å­˜
    if device == 'cuda':
        torch.cuda.empty_cache()
        print("ğŸ§¹ å·²æ¸…ç† GPU ç¼“å­˜")
    
    # 3. åŠ è½½å½’ä¸€åŒ–å‚æ•°
    print("\nğŸ“Š åŠ è½½å½’ä¸€åŒ–å‚æ•°...")
    scaler_path = os.path.join(cache_dir, 'scaler_stats.npz')
    if not os.path.exists(scaler_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°å½’ä¸€åŒ–å‚æ•°æ–‡ä»¶: {scaler_path}")
    
    scaler_data = np.load(scaler_path)
    mean_X = scaler_data['mean_X']
    std_X = scaler_data['std_X']
    mean_Y = scaler_data['mean_Y']
    std_Y = scaler_data['std_Y']
    
    print(f"   Input mean: {mean_X}")
    print(f"   Input std:  {std_X}")
    print(f"   Target mean: {mean_Y}")
    print(f"   Target std:  {std_Y}")
    
    # 4. ç›´æ¥ä»å†…å­˜åŠ è½½æ•°æ®ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®ä½ çš„å®é™…æ•°æ®åŠ è½½æ–¹å¼ä¿®æ”¹ï¼‰
    # å‡è®¾æ•°æ®å·²ç»åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œå¯ä»¥é€šè¿‡æŸç§æ–¹å¼è·å–
    # ä½ éœ€è¦æ ¹æ®å®é™…çš„æ•°æ®åŠ è½½æ–¹å¼ä¿®æ”¹è¿™éƒ¨åˆ†ä»£ç 
    print("\nğŸ“‚ ç›´æ¥ä»å†…å­˜åŠ è½½æ•°æ®...")
    
    # ç¤ºä¾‹ï¼šå‡è®¾æ•°æ®å·²ç»åŠ è½½åˆ°å…¨å±€å˜é‡ä¸­
    # å®é™…ä½¿ç”¨æ—¶ï¼Œä½ éœ€è¦æ ¹æ®ä½ çš„æ•°æ®åŠ è½½æ–¹å¼è·å– X å’Œ Y
    try:
        # å°è¯•ä»å…¨å±€å˜é‡æˆ–å†…å­˜ä¸­è·å–æ•°æ®
        # è¿™é‡Œéœ€è¦æ ¹æ®ä½ çš„å®é™…æ•°æ®åŠ è½½æ–¹å¼ä¿®æ”¹
        import sys
        if 'val_X' in sys.modules['__main__'].__dict__:
            val_X = sys.modules['__main__'].__dict__['val_X']
            val_Y = sys.modules['__main__'].__dict__['val_Y']
            print("   ä»å…¨å±€å˜é‡åŠ è½½éªŒè¯æ•°æ®")
        else:
            raise ImportError("æ— æ³•ä»å…¨å±€å˜é‡è·å–æ•°æ®ï¼Œè¯·ç¡®ä¿æ•°æ®å·²æ­£ç¡®åŠ è½½")
    except Exception as e:
        raise RuntimeError(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
    
    print(f"   éªŒè¯æ•°æ®å½¢çŠ¶: X={val_X.shape}, Y={val_Y.shape}")
    
    # 5. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    val_dataset = MemoryDataset(val_X, val_Y)
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=False
    )
    
    # 6. åˆ›å»ºæ¨¡å‹
    print("\nğŸ—ï¸  åˆ›å»º Transformer PINN æ¨¡å‹...")
    input_dim = len(mean_X)
    output_dim = len(mean_Y)
    
    model = PrinterPINN(input_dim, output_dim)
    
    # 7. åŠ è½½æ¨¡å‹æƒé‡
    print(f"ğŸ“¦ åŠ è½½æ¨¡å‹æƒé‡: {model_path}")
    checkpoint = torch.load(model_path, map_location=device)
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œæ•´çš„æ£€æŸ¥ç‚¹æ–‡ä»¶
    if 'model_state_dict' in checkpoint:
        # å®Œæ•´çš„æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œæå–æ¨¡å‹çŠ¶æ€å­—å…¸
        state_dict = checkpoint['model_state_dict']
        print("   æ£€æµ‹åˆ°å®Œæ•´çš„æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œæå–æ¨¡å‹çŠ¶æ€å­—å…¸")
    else:
        # çº¯æ¨¡å‹æƒé‡æ–‡ä»¶
        state_dict = checkpoint
    
    # å¤„ç† DataParallel æ¨¡å‹
    if 'module.' in list(state_dict.keys())[0]:
        new_state_dict = {}
        for k, v in state_dict.items():
            new_state_dict[k[7:]] = v
        model.load_state_dict(new_state_dict)
    else:
        model.load_state_dict(state_dict)
    
    model = model.to(device)
    model.eval()
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # 8. è¿›è¡Œé¢„æµ‹
    print("\nğŸ”® å¼€å§‹é¢„æµ‹...")
    all_preds = []
    all_targets = []
    total_loss = 0.0
    criterion = nn.MSELoss()
    
    use_amp = device == 'cuda'
    
    with torch.no_grad():
        for batch_idx, (batch_X, batch_Y) in enumerate(val_loader):
            batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)
            
            if use_amp:
                with autocast('cuda'):
                    outputs = model(batch_X)
                    loss = criterion(outputs, batch_Y)
            else:
                outputs = model(batch_X)
                loss = criterion(outputs, batch_Y)
            
            total_loss += loss.item() * batch_X.size(0)
            
            # ä¿å­˜ç»“æœå¹¶è½¬ç§»åˆ° CPU
            all_preds.append(outputs.cpu().numpy())
            all_targets.append(batch_Y.cpu().numpy())
            
            # æ¸…ç† GPU å†…å­˜
            del outputs, loss, batch_X, batch_Y
            if device == 'cuda' and batch_idx % 5 == 0:
                torch.cuda.empty_cache()
            
            if (batch_idx + 1) % 10 == 0:
                print(f"   Batch {batch_idx+1}/{len(val_loader)}")
    
    # 9. åˆå¹¶æ‰€æœ‰é¢„æµ‹
    print("\nğŸ”„ åˆå¹¶é¢„æµ‹ç»“æœ...")
    preds = np.vstack(all_preds)
    targets = np.vstack(all_targets)
    
    # æ¸…ç†å†…å­˜
    del all_preds, all_targets
    gc.collect()
    if device == 'cuda':
        torch.cuda.empty_cache()
    
    # 10. è®¡ç®—å¹³å‡æŸå¤±
    avg_loss = total_loss / len(val_dataset)
    print(f"ğŸ“Š éªŒè¯é›†å¹³å‡æŸå¤±: {avg_loss:.6f}")
    
    # 11. åå½’ä¸€åŒ–
    print("ğŸ”„ åå½’ä¸€åŒ–...")
    preds_real = preds * std_Y + mean_Y
    targets_real = targets * std_Y + mean_Y
    
    # æ¸…ç†ä¸­é—´å˜é‡
    del preds, targets
    gc.collect()
    if device == 'cuda':
        torch.cuda.empty_cache()
    
    # 12. è®¡ç®—å„ç‰¹å¾æŒ‡æ ‡
    print("\nğŸ“ˆ è®¡ç®—å„ç‰¹å¾æŒ‡æ ‡...")
    feature_names = ['temperature_C', 'vibration_disp_m', 'vibration_vel_m_s',
                     'motor_current_A', 'pressure_bar', 'acoustic_signal']
    
    metrics_list = []
    for i, name in enumerate(feature_names):
        pred_i = preds_real[:, i]
        target_i = targets_real[:, i]
        
        mse = np.mean((pred_i - target_i) ** 2)
        mae = np.mean(np.abs(pred_i - target_i))
        rmse = np.sqrt(mse)
        
        # è®¡ç®— RÂ²
        ss_res = np.sum((target_i - pred_i) ** 2)
        ss_tot = np.sum((target_i - np.mean(target_i)) ** 2)
        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
        
        # è®¡ç®— MAPEï¼ˆé¿å…é™¤é›¶ï¼‰
        mask = np.abs(target_i) > 1e-6
        mape = np.mean(np.abs((target_i[mask] - pred_i[mask]) / target_i[mask])) * 100 if np.any(mask) else 0
        
        metrics_list.append({
            'feature': name,
            'MSE': mse,
            'MAE': mae,
            'RMSE': rmse,
            'RÂ²': r2,
            'MAPE (%)': mape
        })
    
    # 13. ç”Ÿæˆå¯è§†åŒ–
    print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    
    # åˆ›å»ºå›¾ç‰‡ä¿å­˜ç›®å½•
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    # å¤§å›¾ï¼šæ‰€æœ‰6ä¸ªç‰¹å¾
    fig, axes = plt.subplots(3, 2, figsize=(16, 12))
    axes = axes.flatten()
    
    n_plot = min(num_samples_to_plot, len(preds_real))
    
    for i, name in enumerate(feature_names):
        ax = axes[i]
        ax.plot(targets_real[:n_plot, i], label='Ground Truth', alpha=0.7, linewidth=2)
        ax.plot(preds_real[:n_plot, i], label='Prediction', linestyle='--', alpha=0.7, linewidth=1.5)
        ax.set_title(f'{name}\nRMSE: {metrics_list[i]["RMSE"]:.4f} | RÂ²: {metrics_list[i]["RÂ²"]:.4f}', 
                    fontsize=11, fontweight='bold')
        ax.set_xlabel('Sample Index')
        ax.set_ylabel('Value')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {save_path}")
    plt.show()
    
    # 14. ç”Ÿæˆæ•£ç‚¹å›¾ï¼ˆé¢„æµ‹ vs çœŸå®å€¼ï¼‰
    scatter_path = save_path.replace('.png', '_scatter.png')
    fig2, axes2 = plt.subplots(3, 2, figsize=(16, 12))
    axes2 = axes2.flatten()
    
    for i, name in enumerate(feature_names):
        ax = axes2[i]
        ax.scatter(targets_real[:, i], preds_real[:, i], alpha=0.1, s=1)
        ax.plot([targets_real[:, i].min(), targets_real[:, i].max()],
                [targets_real[:, i].min(), targets_real[:, i].max()], 
                'r--', linewidth=2, label='Perfect Prediction')
        ax.set_xlabel('Ground Truth')
        ax.set_ylabel('Prediction')
        ax.set_title(f'{name} - Scatter Plot', fontsize=11, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.axis('equal')
    
    plt.tight_layout()
    plt.savefig(scatter_path, dpi=150, bbox_inches='tight')
    print(f"âœ… æ•£ç‚¹å›¾å·²ä¿å­˜: {scatter_path}")
    plt.show()
    
    # 15. ä¿å­˜æŒ‡æ ‡æŠ¥å‘Š
    print("\nğŸ“ ä¿å­˜æŒ‡æ ‡æŠ¥å‘Š...")
    os.makedirs(os.path.dirname(save_metrics), exist_ok=True)
    
    with open(save_metrics, 'w', encoding='utf-8') as f:
        f.write("=" * 70 + "\n")
        f.write("Transformer PINN æ¨¡å‹æ€§èƒ½æŒ‡æ ‡æŠ¥å‘Š\n")
        f.write("=" * 70 + "\n\n")
        f.write(f"æ¨¡å‹æ–‡ä»¶: {model_path}\n")
        f.write(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}\n")
        f.write(f"éªŒè¯é›†å¹³å‡æŸå¤±: {avg_loss:.6f}\n\n")
        
        f.write("-" * 70 + "\n")
        f.write("å„ç‰¹å¾è¯¦ç»†æŒ‡æ ‡\n")
        f.write("-" * 70 + "\n\n")
        
        for metrics in metrics_list:
            f.write(f"ç‰¹å¾: {metrics['feature']}\n")
            f.write(f"  MSE (å‡æ–¹è¯¯å·®):     {metrics['MSE']:.6f}\n")
            f.write(f"  MAE (å¹³å‡ç»å¯¹è¯¯å·®): {metrics['MAE']:.6f}\n")
            f.write(f"  RMSE (å‡æ–¹æ ¹è¯¯å·®):  {metrics['RMSE']:.6f}\n")
            f.write(f"  RÂ² (å†³å®šç³»æ•°):      {metrics['RÂ²']:.6f}\n")
            f.write(f"  MAPE (å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®): {metrics['MAPE (%)']:.2f}%\n\n")
    
    print(f"âœ… æŒ‡æ ‡æŠ¥å‘Šå·²ä¿å­˜: {save_metrics}")
    
    # 16. æ‰“å°æ‘˜è¦
    print("\n" + "=" * 70)
    print("ğŸ“Š æ€§èƒ½æ‘˜è¦")
    print("=" * 70)
    for metrics in metrics_list:
        print(f"{metrics['feature']}:")
        print(f"  RMSE: {metrics['RMSE']:.4f}, RÂ²: {metrics['RÂ²']:.4f}, MAPE: {metrics['MAPE (%)']:.2f}%")
    
    print("\n" + "=" * 70)
    print("âœ… å¯è§†åŒ–å®Œæˆï¼")
    print("=" * 70)
    
    return metrics_list, avg_loss

def main():
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description='Evaluate Transformer PINN model')
    parser.add_argument('--model_path', type=str, default='best_pinn_model.pth',
                       help='Path to the model weights file (default: best_pinn_model.pth)')
    parser.add_argument('--cache_dir', type=str, default='./data_cache/',
                       help='Directory containing cached data (default: ./data_cache/)')
    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu',
                       help='Device to run on (cuda or cpu)')
    parser.add_argument('--batch_size', type=int, default=1024,
                       help='Batch size for evaluation (default: 1024)')
    parser.add_argument('--num_samples', type=int, default=200,
                       help='Number of samples to plot (default: 200)')
    parser.add_argument('--save_path', type=str, default='image/pinn_prediction_visualization.png',
                       help='Path to save visualization image (default: image/pinn_prediction_visualization.png)')
    parser.add_argument('--metrics_path', type=str, default='image/pinn_metrics_report.txt',
                       help='Path to save metrics report (default: image/pinn_metrics_report.txt)')
    
    args = parser.parse_args()
    
    # è°ƒç”¨è¯„ä¼°å‡½æ•°
    metrics, val_loss = load_model_and_visualize(
        model_path=args.model_path,
        cache_dir=args.cache_dir,
        device=args.device,
        batch_size=args.batch_size,
        num_samples_to_plot=args.num_samples,
        save_path=args.save_path,
        save_metrics=args.metrics_path
    )

if __name__ == "__main__":
    main()
